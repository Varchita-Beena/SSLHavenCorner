# SSLHavenCorner
Comprehensive coverage of self-supervised learning in both computer vision and natural language processing domains. This entails detailed explanations of models, (sometimes with code snippets), discussions on various loss functions, and insights into the underlying mechanisms.</br>

### Self-supervised learning
1. [A surprisingly simple technique to control the pretraining bias for better transfer: Expand or Narrow your representation](https://github.com/Varchita-Beena/SSLHavenCorner/blob/SSLIncoming/Expand%20or%20Narrow%20your%20Representation.md)

### [Understanding Contrastive Loss
1. [What Makes for Good Views for Contrastive Learning?](https://github.com/Varchita-Beena/SSLHavenCorner/blob/main/Understanding%20Contrastive%20Loss%20-%20Wing%201.md)
2. Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere (Incoming)

### Self Supervised Learning (Images)
1. [Deep Cluster for Unsuperervised Learning of Visual Features](https://github.com/Varchita-Beena/SSLHavenCorner/blob/main/Deep%20Clustering.md)
2. [Momentum Contrast for Unsupervised Visual Representation Learning](https://github.com/Varchita-Beena/SSLHavenCorner/blob/main/Momentum%20contrast.md)

## Mutil-Modal
1. [Learning Transferable Visual Models From Natural Language Supervision](https://github.com/Varchita-Beena/SSLHavenCorner/blob/main/CLIP.md)
2. [Image Segmentation Using Text and Image Prompts](https://github.com/Varchita-Beena/SSLHavenCorner/blob/main/CLIP_Seg.md)
